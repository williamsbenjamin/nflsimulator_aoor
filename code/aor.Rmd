---
title: "Simulation-Based Decision Making in the NFL using NFLSimulatoR"
titlerunning: Decision Making in the NFL
authorrunning: Williams, Palmquist, and Elmore
thanks: | 
   Correspondence should be addressed to Benjamin Williams.
authors: 
- name: Benjamin Williams
  address: Department of Business Information and Analytics, Daniels College of Business, University of Denver
  email: Benjamin.Williams@du.edu
- name: Will Palmquist
  address: Department of Business Information and Analytics, Daniels College of Business, University of Denver
  email: Will.Palmquist@du.edu
- name: Ryan Elmore
  address: Department of Business Information and Analytics, Daniels College of Business, University of Denver
  email: Ryan.Elmore@du.edu
keywords:
- sports statistics
- analytics
- NFL

#PACS: 
#- PAC1
#- superPAC
    
MSC:
# - MSC code 
# - MSC code

abstract: |
  In this paper, we introduce an R software package for simulating plays and 
  drives using play-by-play data from the National Football League. We 
  highlight that the package is particularly useful as a data-driven tool for
  evaluating potential strategies or rule changes within the league. We
  demonstrate its utility by evaluating the oft-debated strategy of "going
  for it" on fourth down and a whether or not teams should pass more than 
  the current standard. 

bibliography: bibliography.bib
bibstyle: spbasic
# bibstyle options spbasic(default), spphys, spmpsci

output: rticles::springer_article
---
```{r global-options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

```{r pkgs, warning = F, message = F, include = F}
library(dplyr)
library(ggplot2)
library(scales)
library(lubridate)
library(cowplot)
library(knitr)
library(kableExtra)
```

```{r data, warning = F, message = F, include = F, cache = T}
options(dplyr.summarise.inform = FALSE)
Playoffs <- readRDS(file = "../data_2/playoffs_sims.rds")
all_1819 <- readRDS(file = "../data_2/all_1819.rds")
#qbr_sims <- readRDS(file = "../data/QBR_sims.rds")
plays <- readRDS(file = "../data_2/pbp-data-1819.rds")
qbr_thirds_sims <- readRDS(file = "../data_2/QBR_thirds_sims.rds")
fourths_sims <- readRDS(file = "../data_2/fourth_down_sims.rds")
fourths_sims$Scenario <- as.factor(fourths_sims$Scenario)
yds_less_than <- readRDS(file = "../data_2/yds_less_than_sims.rds")
pass_run <- plays %>% 
  dplyr::filter(., play_type %in% c("run", "pass"), down %in% 1:3) %>% 
  dplyr::mutate(., year = lubridate::year(game_date)) %>% 
  dplyr::group_by(., year, play_type) %>%
  dplyr::summarize(., n = n()) %>% 
  dplyr::mutate(prop = n / sum(n))
# Group by drives and caculate percent score and average pts per drive
scores <- Playoffs %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  dplyr::mutate(., score = ifelse(points > 0, 1, 0),
                score_type = ifelse(points == 3, "FG",
                                    ifelse(points == 7, "TD", "NoScore"))) %>% 
  dplyr::group_by(., teams, proportion, score_type) %>%
  dplyr::summarize(., score_ct = n()) %>% 
  dplyr::group_by(., teams, proportion) %>%
  dplyr::mutate(p = score_ct/sum(score_ct)) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(., upper = p + 2*sqrt(p*(1 - p)/10000),
                lower = p - 2*sqrt(p*(1 - p)/10000),
                year = ifelse(grepl("2018", teams), "2018", "2019"),
                playoffs = ifelse(grepl("Non", teams), "No", "Yes"))

all_scores <- all_1819  %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  dplyr::mutate(., score = ifelse(points > 0, 1, 0)) %>% 
  dplyr::group_by(., year, proportion) %>%
  dplyr::summarize(., p = sum(score)/n(),
                   score_avg = sum(points)/n()) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(., upper = p + 2*sqrt(p*(1 - p)/10000),
                lower = p - 2*sqrt(p*(1 - p)/10000))
all_scores <- all_scores %>% 
  dplyr::mutate(full_year = if_else(year == 18,2018,2019))
all_scores_by_type <- all_1819  %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  dplyr::mutate(., score = ifelse(points > 0, 1, 0),
                full_year = ifelse(year == 18, 2018, 2019),
                score_type = ifelse(points == 3, "FG",
                                    ifelse(points == 7, "TD", "NoScore"))) %>% 
  dplyr::group_by(., full_year, proportion, score_type) %>%
  dplyr::summarize(., score_ct = n()) %>% 
  dplyr::group_by(., full_year, proportion) %>%
  dplyr::mutate(p = score_ct/sum(score_ct)) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(., upper = p + 2*sqrt(p*(1 - p)/10000),
                lower = p - 2*sqrt(p*(1 - p)/10000))

qbr_scores <- qbr_thirds_sims %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  dplyr::mutate(., score = ifelse(points > 0, 1, 0),
                full_year = ifelse(year == 18, 2018, 2019),
                qbr_short = ifelse(grepl("High", RTG), "High",
                                   ifelse(grepl("Low", RTG), "Low", "Mid")),
                score_type = ifelse(points == 3, "FG",
                                    ifelse(points == 7, "TD", "NoScore"))) %>% 
  dplyr::group_by(., full_year, proportion, qbr_short, score_type) %>%
  dplyr::summarize(., score_ct = n()) %>% 
  dplyr::group_by(., full_year, proportion, qbr_short) %>%
  dplyr::mutate(., p = score_ct / sum(score_ct)) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(., upper = p + 2*sqrt(p*(1 - p)/10000),
                lower = p - 2*sqrt(p*(1 - p)/10000))
```
\definecolor{dured}{RGB}{144, 0, 0}

# Introduction {#intro}

Data-driven decision making is a ubiquitous strategy in today’s marketplace and is becoming increasingly common amongst professional sports organizations. From the Major League Baseball's Moneyball movement [@lewis03] to the Moreyball strategies employed by the National Basketball Association's Houston Rockets [@walsh19], analytics are no longer the sole purview of the academy as teams try to improve their performance by investigating the data. The general consensus, however, is that the National Football League (NFL) lags behind other professional sports leagues in their use of analytics [@clark]. This does seem to be changing, as evidenced by a recent hiring trend of data analysts to NFL teams [@loque19], as well as within the league office in New York.

<!-- There are even peer-reviewed journals dedicated to analytics in athletics (e.g., *Journal of Quantitative Analysis in Sports* and *Journal of Sports Analytics*). -->

In the NFL, perhaps the most widely debated research question regards the decision of going for it on fourth down. This has also been the subject of several academic articles [@romer2006firms; @yam2019lost], the New York Times “4th down bot” [@fdbot; @causey15], and a new calculator from sports analyst Ben Baldwin [@baldwin_athletic]. The consensus among researchers and analysts is NFL coaches tend to be too conservative in their fourth-down calls, often preferring to kick the football (punt or field goal attempt) when the data suggests they should pass or run the ball. 

<!-- \textcolor{dured}{Should we add the reference to the new 4th down bot here?} -->

While the decision to go for it on fourth down is much discussed, there are a plethora of other strategies a team may wish to investigate. Potential strategies for deeper investigation range from the frequency and type of plays run, the use of a team's (limited) timeouts during a game, defensive alignment, and so on. The seemingly infinite possibilities for NFL strategy evaluation made us wonder how one could determine which strategies offer the best chance of winning. Some attempt has been done for strategies such as passing versus running the football. In the sole peer-reviewed article that we are aware of, @levitt09 found NFL teams did not pass as much as they should. @hermsmeyer similarly noted, in an article for the data journalism website fivethirtyeight.com, that even though the NFL has transitioned to become a more passing heavy league, teams should still pass more. Apart from the passing versus rushing and fourth down decision making, there is a lack of research regarding NFL strategies in the literature. 

In this paper we present an R software package, `NFLSimulatoR`, and an analytically rigorous method for analyzing NFL strategies. Our method consists of simulating strategies via the sampling of NFL play-by-play datasets that were realized in previous seasons. This simulation method is flexible and allows for the investigation of many possible strategies and offers a tool for informed decision making with respect to sport performance. We have embedded the simulation framework into an open source software package to share the method with the broader sports analytics community. The rest of the paper is outlined as follows. In the next section we present the R software package we wrote for simulating NFL strategies. Section 3 describes the use of the software package for the two strategies we have discussed thus far: fourth down decision making and passing versus rushing. Finally, we offer some concluding thoughts about using (and contributing to) the package moving forward and other discussions in the final section. 

# NFLSimulatoR {#sec:nfl_sim}

The ideas presented in this paper are, in part, inspired by a blog post by Mike Lopez, currently the Director of Data and Analytics for the NFL, in which he used a simulation-based approach to investigate a potential overtime rule change in the NFL [@statsbylopez]. In contrast to the one-off solution presented on his blog, we provide a robust software platform for assessing NFL strategies in the `NFLSimulatoR` R package. Our desire is for the wider analytics community to use this package, extend our work, and study other strategies in a analytically sound manner.  

<!-- We chose to write the software in the R language [@r] because it is open source and encourages collaboration as a result. The package is dynamic and can be updated based on user needs, recommendations, and insights. Additionally, the R software enjoys an extensive and supportive online community making it ideal for individuals or teams of analysts alike. -->

The ideas embedded in `NFLSimulatoR` are simple, yet extremely powerful. The key feature is that we rely on simulations of actual NFL play-by-play data to evaluate potential strategies. We define a strategy broadly as any set of principled decisions consistently made by an NFL team during a game. An example, albeit possibly extreme, is for a team to employ only passing plays rather than a mixture of passes and runs while on offense. This is a simple strategy, but one we can nonetheless examine using our package. To examine a particular strategy, we sample plays satisfying the criteria of the strategy at hand. Going back to our simplistic example, we would sample only passing plays if we wanted to see what happened when a team only passes the football. 

Sampling data to make estimates, inferences, or decisions about a larger population is at the core of statistics and lends important rigor to our method. In our package, we select probability samples according to a simple random sample with replacement from our population of interest (NFL play-by-play data) to produce unbiased and representative results. An excellent resource for more on statistical sampling can be found in @lohr.

The package relies on NFL play-by-play data available via the NFL's Application Programming Interface. These datasets are accessible within R using either the `nflscrapR` or the `nflfastR` R packages [@scrapr; @fastr] or by downloading it directly from the nflscrapR-data or nflfastR-data websites [@yurko; @baldwin]. The NFLSimulatoR package includes two functions, `download_nflscrapr_data()` and `download_nflfastr_data()`, for directly downloading regular-, pre-, or post-season NFL play-by-play data from either source for several years, currently from 2009 - 2019. Each year contains approximately 48,000 plays of data. In addition, we include a function called `prep_pbp_data()` to eliminate extraneous information and prepare the NFL data for use in `NFLSimulatoR` functions.

Our package is built primarily on the function `sample_play()`. This function samples from NFL data according to a given strategy for a particular down and distance. The strategy is passed to the function via the `strategy` parameter. Down and distance information refer to what down it is (1 - 4), how many yards are required for a first down, and the yardline at which the play occurs (1 - 99). The down is passed to the function via the `what_down` parameter, the distance to go is passed via the `yards_to_go` parameter, and the yardline is passed via the `yards_from_own_goal` parameter. Our sampling is done randomly and so we are confident in the outcomes from the simulations. However, some combinations of sampling parameters (strategy, down, distance, yardline) rarely occur in an NFL game. For example, it may be there are few or no plays where a team had the ball on 3rd down, on the 47th yardline, with 15 yards to go for a first down, and chose to run the ball. In such cases we widen our sampling range to include plays from yardlines close the to the yardline of interest or with one less yard to go for a first down (the user can also choose a window to expand the yardline selection via the `window_yards_from_own_goal` parameter). We have built flexibility into the `sample_play()` function so the user can seamlessly implement it in their unique settings.

The other main function of interest in the package is called `sample_drives()`. This allows the user to simulate a series of plays by one team (a drive) following some specific strategy versus another team employing a "normal" strategy. By "normal" we mean the plays of the opposing team are simply sampled at random from  all plays without a specific strategy in mind. The `sample_drives()` function shows how a specific strategy is expected to perform if implemented during an NFL game when the opposing team is employing the status quo. The function can either sample drives until one team scores, or it can sample a single drive and return the outcome of the drive (i.e., touchdown, field goal, punt, or turnover). By simulating many drives one can identify statistics such as expected points per drive and proportion of drives resulting in a score for a variety of strategies. The `sample_drives()` function takes parameters for the number of simulations to be run (`n_sims`), the starting yardline of the simulations (`from_yard_line`), the strategy (`strategy`), and if the simulation is of a single drive (`single_drive`). Within `sample_drives()`, the function `down_distance_updater()` updates the down, distance, and yards to go and then samples the next play from all plays satisfying the updated criteria. 

To demonstrate the use of this software and to offer an idea of how to extend our work, we provide two strategies in the package. The first is a strategy related to fourth-down decision making and the second is associated with how often a team should pass (or run) the football. Within the fourth down strategy we include several sub-stratgies to make a decision about going for it or not on fourth down. As mentioned above, the fourth down strategy has been studied in the academic domain, see e.g. @yam2019lost and @romer2006firms. We include it in this manuscript due to its popularity and to give our own perspective on this well-known problem. In the next section, we discuss these two strategies in more detail.

The `NFLSimulatoR` package is available on CRAN (Comprehensive R Archive Network) and the latest developmental version is available on github. Adding this package to CRAN was an important step to make sure our package passed rigorous software checks and to make installation simpler. At the time of this writing, `NFLSimulatoR` has been available on CRAN for less than two months and has over 1000 downloads, showing the enthusiasm for the package by the sport analytics community. Additional package details related to issues, recent changes, etc. can be found at the [NFLSimulatoR website](http://datacolorado.com/NFLSimulatoR). The package can be installed within R using either option given below. 

```{r, eval = F}
## From CRAN
install.packages("NFLSimulatoR")
## From Github
install.packages("remotes")
remotes::install_github("rtelmore/NFLSimulatoR")
```

# Applications {#sec:apps}

## Fourth Down Strategy

The first strategy we examine concerns fourth down decision making. This is one of the most well-known and discussed NFL strategies. On a fourth down the offensive team has two options: go for it or kick. If they kick, they can either punt the ball and allow the other team to take offensive position or kick a field goal. The other option a team has on fourth down is to attempt to run or pass the ball and gain enough yards for a first down. Historically, NFL coaches tend to not go for it on fourth down unless time is running out and/or the only possible way to win the game involves increasing the risk of a turnover for the potential benefit of a first down. However, thanks to the analytics movement, teams are beginning to challenge the status quo.

In 2006, Romer began the discussion about optimal decision making on fourth down by estimating the expected point value of kicking versus going for it on fourth down. This was done by estimating the value of a team having the ball at each yardline on the field. These values were estimated from NFL play-by-play data from 1998, 1999, and 2000 [@romer2006firms]. This work was updated in 2013 via the New York Times' Fourth Down Bot [@fdbot]. Burke and Quealy use a similar calculation of the value of being at each yardline and then estimate the probability of gaining enough yards for a first down. The expected points for some fourth down can be calculated as the product of the probability of securing a first down and the point value of a first down at the specific yardline added to the product of the probability of not securing a fourth down and the point value of the other team taking possesion at the given yardline.

The estimated value of being at a given yardline takes into account field goals and the expectation can be either positive or negative. If it is positive, the Fourth Down Bot recommends going for it on fourth down. Yam and Lopez (2019) implemented the Fourth Down Bot in a causal analysis and determined, on average, if teams employed the (more aggresive) strategy of the Fourth Down Bot they would enjoy approximately 0.4 more wins per year. In the NFL where there are only 16 games in a season, 0.4 is a substantial increase in wins. For further examination into the history of fourth down decision making see @yam2019lost.

Because this strategy is of such interest we include it in our package. We offer five sub-strategies regarding decision making on fourth downs to compare various methods. The first is called the *empirical* sub-strategy. Here, our functions simply select the fourth down play at random from among all similar plays (i.e., similar with respect to down, distance and yardline). The majority of the time this will be a punt or field goal attempt, but there are occasions where a team may try for a fourth down (perhaps if there is very little yardage needed for a first down and the yardline is close to the opposing endzone). The second sub-strategy is *always go for it* and samples non-kicking plays from the given down and distance. In this sub-strategy we do not require the sampling to be exclusively from fourth down plays. In fact, we expand the pool of potential plays to sample from on each of downs two through four. That is, we sample from downs $d$ and $d-1$ on down $d$, for $d = 2, 3, 4$. We assume the impact of, and mental anxiety among, players due to it being fourth down is negligible because the defensive team would have similar anxieties, the players are professional and should be more immune to such inhibitions, and because previous literature followed this procedure. The third sub-strategy is *never go for it* and in it the team always punts or kicks a field goal. This offers us a conservative strategy to study, and we simply sample kicks (and their outcome) from the given location.

The fourth sub-strategy is *go for it if yardage is smaller than Y*. Here we let the user set the parameter $Y$ to be the value of the yards required for a first down. If the distance for a first down is less than or equal to $Y$ the strategy says to go for it, and to kick if the distance is greater than or equal to $Y$. This allows the examination of a stricter sub-strategy but one offering a tradeoff between *always go for it* and *never go for it*. This sub-strategy is likely more palatable for NFL teams since having a rule to go for it on fourth if there is always less than, say, 1 yard to go for a first down might be more acceptable than always going for it. The final sub-strategy is *expected points*. Here we use the expected points estimated from the `nflscrapR` R package to find the expected points at each yardline on the field. We further empirically estimate the probability of gaining a first down and making a field goal. Then we solve for the expected value of going for it, punting it, and kicking a field goal. The decision is made by selecting the choice which maximizes this expected points value. This last sub-strategy is the most analytically reliant, and best mirrors current literature. Because we offer these sub-strategies within a free software package they can be re-run each season as more data becomes available allowing analysts to make recommendations which include the most recent NFL data.

We compare these sub-strategies by plotting the percent of drives resulting in no score, a field goal, or a touchdown for the five sub-strategies. For the *go for it if yardage is smaller than Y* option we let *Y=5*. For this and subsequent fourth down analyses, we only keep plays occuring before the final 2 minutes of each half of the game and only plays where one team is within 28 points of the other. This allows us to remove any plays that result from extreme decision making because the outcome of the game is all but determined. We use play-by-play data from both 2018 and 2019. 

For the simulations, we generate 10000 drives for each sub-strategy starting at the 25 yard line for all plays from these two regular seasons. This corresponds to the usual starting position to begin a half or after an opposing team scores (assuming the kickoff is a touchback). For each drive we use the `sample_drives()` function and set the `single_drive` argument equal to `TRUE`. Thus, we only care about simulating one drive and storing its outcome for each simulated drive. In other words, we start each drive with first down and ten yards to go from the 25 and sample plays accordingly. The summarized results are displayed Figure \ref{fig:fourth-down-perc-score}.

```{r fourth-down-perc-score, fig.width = 4.75, fig.height=2.75, fig.cap = "\\label{fig:fourth-down-perc-score}The percentage of simulated drives that resulted in no score (green), a field goal (orange), or a touchdown (purple) in 2018 and 2019, for the fourth-down sub-strategies", echo = F}

# scores <- fourths_sims %>% 
#   dplyr::filter(., end_drive == TRUE) %>%
#   dplyr::mutate(score = ifelse(points > 0, 1, 0)) %>% 
#   dplyr::group_by(.,Scenario) %>%
#   dplyr::summarize(.,score_pct = sum(score)/n(),
#                    score_avg = sum(points)/n(),.groups = "keep")
pct_type <- fourths_sims %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  dplyr::mutate(score = ifelse(points > 0, 1, 0),
                score_type = ifelse(points == 3,"FG",ifelse(points == 7,"TD","NoScore"))) %>%
  dplyr::group_by(.,Scenario,score_type) %>%
  dplyr::summarize(.,score_ct = n(),.groups = "keep") %>% 
  dplyr::group_by(.,Scenario) %>%
  dplyr::mutate(score_pct = score_ct/sum(score_ct),.groups = "keep")

# Percent Score Figure
p_score <- ggplot(data = subset(pct_type, score_type %in% c("FG", "TD")),
                  aes(x = Scenario, y = score_pct,fill = score_type)) +
  geom_bar(stat = 'identity', position = "stack") +  
 ylab("Percent Score") +
  scale_x_discrete(breaks = c("always_go_for_it","empirical","exp_pts",
                            "never_go_for_it","yds_less_than_5"),
                 labels = c("Always\n go for it", "Empirical", "Expected\n points",
                            "Never\n go for it","Yards smaller\n than 5")) + 
  scale_fill_brewer("Score Type",
                      breaks = c("FG","TD"),
                      labels = c("FG","TD"),
                    palette = "Dark2") +
  theme_bw() +
  theme(legend.text = element_text(size = 8),
        legend.title = element_blank())

p_score <-  fourths_sims %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  count(Scenario,points) %>% 
  mutate(pct = n/10000) %>% 
  mutate(points = factor(points)) %>%
  ggplot(aes(x = factor(Scenario,levels = c("always_go_for_it","empirical","yds_less_than_5","exp_pts",
                            "never_go_for_it")), y = pct,fill = points),
         show.legend = F) +
  geom_col(position = "stack",show.legend = F) +
  ylab("Percent of Drives") + 
  xlab(NULL) +
scale_x_discrete(breaks = c("always_go_for_it","empirical","exp_pts",
                            "never_go_for_it","yds_less_than_5"),
                 labels = c("Always\n go for it", "Empirical", "Expected\n points",
                            "Never\n go for it","Yards smaller\n than 5")) + 
  scale_y_continuous(limits = c(0, 1), breaks = seq(0.0, 1, by = .1),
                     #labels = scales::percent,
                     labels = percent_format(accuracy = 1)) +
    scale_fill_brewer("Score Type",
                      breaks = c("0","3","7"),
                      labels = c("0","FG","TD"),
                    palette = "Dark2") +
  theme_bw() + 
  theme(legend.title = element_blank(),
        legend.key.size = unit(0.75,"line"),
        plot.title = element_text(size = 10))
p_score
```

From this figure we see the *never go for it* strategy offers the largest probability for scoring on a single drive with the majority of the scores coming from field goals. The *expected points* strategy has the second largest percentage of simulated drives resulting in a score, followed by *yardage smaller than 5 yards*, and then the *empirical* sub-strategy. For further investigation, in Table \ref{tab:tab1} we examine the percent of drives resuling in a field goal (FG) or touchdown (TD), the average score per drive (assuming a touchdown always results in 7 points), and a 95\% confidence interval for the average score, for the 5 sub-strategies.

```{r table1, full_width = FALSE, echo=F}
fourths_table <- fourths_sims %>% 
  mutate(Scenario = recode(Scenario,
                               "always_go_for_it" = "Always go for it",
                               "empirical" = "Empirical",
                               "exp_pts" = "Expected points",
                               "never_go_for_it" = "Never go for it",
                               "yds_less_than_5" = "Yards less than 5")) %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  dplyr::mutate(score = ifelse(points > 0, 1, 0)) %>% 
  dplyr::group_by(.,Scenario) %>%
  dplyr::summarize(.,
                   #len = n(),
                   pct_fg = paste0(as.character(round(100*sum(is_field_goal)/10000),2),"%"),
                   pct_td = paste0(as.character(round(100*sum(is_td_offense)/10000),2),"%"),
                   mean_score = round(mean(points),2),
                   lower_ci = round(mean(points) - (2*sd(points)/sqrt(n())),2),
                   upper_ci = round(mean(points) + (2*sd(points)/sqrt(n())),2),
                   .groups = "keep") %>% 
  ungroup() %>% 
  rename("Sub-strategy" = "Scenario") %>% 
  rename("Mean Score" = "mean_score",
         "% of Drives Ending in FG" = "pct_fg",
         "% of Drives Ending in TD" = "pct_td",
         "Lower 95% CI for Score" = "lower_ci",
         "Upper 95% CI for Score" = "upper_ci") 
fourths_table %>%
  knitr::kable(booktabs = T,escape = F,format = "markdown",caption ="\\label{tab:tab1} Description of 10000 simulations (2018 and 2019 data) for each fourth down sub-strategy") %>%
  row_spec(0, align = "r")
```

From Table \ref{tab:tab1}, the fourth down sub-strategy with the largest average points per simulated drive is *always go for it* (average of 2.28 points) followed by *yardage smaller than 5 yards* (average of 2.24 points), and *expected points* (average of 2.19 points). We also see the *always go for it* sub-strategy is boom or bust resulting in only touchdowns or no scores. Interestingly the *yardage smaller than 5 yards* has an average score similar to *always go for it*, yet it does recommend field goals to be taken. The confidence interval for the *yardage smaller than 5 yards* mean score is also narrower than that for *always go for it*. Taking this into account along with the fact that the averages of these two sub-strategies are so close, a recommendation for a team nervous about always going for it on fourth down might be to always go for it if there are less than five yards to go for a first down, regardless of field position. Figure \ref{fig:fourth-down-perc-score} shows this strategy will produce scoring drives more often and has nearly the highest average score per drive. 

If a team wishes to pursue this sub-strategy (going for it on fourth if the yards to go is less than five yards) a logical next question is: what about other *yards to go* values? That is, what if the team went for it if the yards required for a first down are 4, or 6, or something else entirely? Figure 2.1 shows the percent of drives resulting in a score for a range of $Y$ values. Figure 2.2 displays the average (and 95% confidence interval) score per drive for the various $Y$ values, and Figure 2.3 gives the average (and 95% confidence interval) yardline at which the ball is turned over when the drive does not result in a score.

```{r yds-less-than, fig.width = 5, fig.height=3, fig.cap = "\\label{fig:yds-less-than} 2.1: The percentage of simulated drives that resulted in a field goal (green) ora touchdown (orange); 2.2: Average score per drive for the *yardage less than Y yards* sub-strategy as a function of $Y$; 2.3: Average turnover yardline resulting from the *yardage less than Y yards* sub-strategy as a function of $Y$", echo = F,warning = FALSE,message=FALSE}

yds_strats <- yds_less_than %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  dplyr::mutate(score = ifelse(points > 0, 1, 0),
                score_type = ifelse(points == 3,"FG",ifelse(points == 7,"TD","NoScore"))) %>%
  dplyr::group_by(.,Scenario,score_type) %>%
  dplyr::summarize(.,score_ct = n(),.groups = "keep") %>% 
  dplyr::group_by(.,Scenario) %>%
  dplyr::mutate(score_pct = score_ct/sum(score_ct))

yds_strats_ci <- yds_less_than %>% 
  dplyr::filter(., end_drive == TRUE) %>%
  dplyr::mutate(score = ifelse(points > 0, 1, 0)) %>% 
  dplyr::group_by(.,Scenario) %>%
  dplyr::summarize(.,len = n(),
                   mean_score = mean(points),
                   lower_ci = mean(points) - (2*sd(points)/sqrt(n())),
                   upper_ci = mean(points) + (2*sd(points)/sqrt(n())),
                   .groups = "keep")
yds_strats_ci$Scenario <- as.numeric(substr(yds_strats_ci$Scenario,15,nchar(yds_strats_ci$Scenario)-2))
yds_strats$Scenario <- as.numeric(substr(yds_strats$Scenario,15,nchar(yds_strats$Scenario)-2))
# Percent Score Figure
yds_score <- ggplot(data = subset(yds_strats,score_type %in% c("FG", "TD")),
                  aes(x = reorder(Scenario,Scenario), y = score_pct,fill = score_type)) +
  geom_bar(stat = 'identity', position = "stack") +  
  scale_fill_brewer("Score Type",
                      breaks = c("FG","TD"),
                      labels = c("FG","TD"),
                    palette = "Dark2") +
  xlab("Yards less than") + 
  ylab("Percent Score") +
  scale_y_continuous(limits = c(0, .4), breaks = seq(0.0, .4, by = .1),
                     #labels = scales::percent,
                     labels = percent_format(accuracy = 1)) +
  theme_bw() +
  theme(legend.title = element_blank(),
        legend.key.size = unit(0.75,"line"),
        plot.title = element_text(size = 10))


yds_perc <- ggplot(data = yds_strats_ci,
       aes(x = reorder(Scenario,Scenario), y = mean_score),show.legend = F) +
  geom_point(position = position_dodge(width = .05),show.legend = F) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), 
                position = position_dodge(.05),
                show.legend = F) +
  ylab("Average Score") +
  xlab("Yards less than") +
  guides(fill = F) +
  theme(plot.title = element_text(size = 10))+
  theme_bw()

no_scores_ci <- yds_less_than %>% 
  dplyr::filter(., points == 0, end_drive == TRUE) %>% 
  dplyr::group_by(.,Scenario) %>%
  dplyr::summarize(.,len = n(),
                   mean_yds = mean(new_yfog),
                   lower_ci = mean(new_yfog) - (2*sd(new_yfog)/sqrt(n())),
                   upper_ci = mean(new_yfog) + (2*sd(new_yfog)/sqrt(n())),
                   .groups = "keep")
#substring extract number
no_scores_ci$Scenario <-as.numeric(substr(no_scores_ci$Scenario,15,nchar(no_scores_ci$Scenario)-2))

turn_yds <- ggplot(data = no_scores_ci,
       aes(x = reorder(Scenario,Scenario), y = mean_yds),show.legend = F) +
  geom_point(position = position_dodge(width = .05),show.legend = F) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci),
                position = position_dodge(.05),
                show.legend = F) +
  ylab("Average\n Turnover Yardline") +
  xlab("Yards less than") +
  guides(fill = F) +
  theme(plot.title = element_text(size = 10))+
  theme_bw()

plot_grid(plot_grid(NULL,yds_score,NULL,ncol=3,
                    rel_widths=c(0.2,0.7,0.1),labels =c(NULL,"2.1",NULL),label_size = 10,hjust = -3),
          plot_grid(yds_perc,turn_yds,ncol =2,labels = c("2.2","2.3"),label_size = 10,vjust = 0.2,hjust = -2.5),
          ncol = 1)
```

In Figure 2.1 the largest percent score value (of about 38\%) is nearly exactly achieved by $Y$ values of 3, 4, and 5. Figure 2.2 shows the $Y$ values of 8 has the top average score per drive values, and this average decreases as $Y$ descreases. Figure 2.3 shows the average turnover yardline gets further away from the offensive teams goal for larger values of $Y$. Taking all this together, a value of 5 yards may be the best option for the fourth down substrategy *go for it if yardage less than $Y$* because it has nearly the highest percent score value, a higher average score than all smaller $Y$ values, a more advantageous average turnover yardline than all larger $Y$ values, and (speculatively) may be more acceptable by NFL coaching staffs than a value of, say, $Y = 8$.

Here, we caution the reader that this is by no means a causal investigation of fourth down strategies. Indeed, we could further analyze the data by evaluating the performance of a specific sub-strategy amongst better or worse teams, but do not do so as our primary purpose is to demonstrate the usefulness of the `NFLSimulatoR` package and its core functionality.

<!-- In this section we have preliminarily examined five fourth down sub-strategies. The figures and analysis we show are easily implemented in the NFLSimulatoR package. From this brief analysis, we certainly suggest teams go for it on fourth down more often than they currently do (see Figure \ref{fig:fourth-down-perc-score} and Table \ref{tab:tab1}).  -->

## Run/Pass Percentage 

@levitt09 and @hermsmeyer argue NFL teams should pass more often. In this section we investigate this thesis using the simulation-based approach of `NFLSimulatoR`. Though perhaps simple on its surface, examining a strategy having to do with the proportion of plays that are a pass instead of a run proves interesting. Even if the NFL is not as analytically forward as other professional sports leagues, the league seems to be trending towards passing more. The `NFLSimulatoR` package includes a strategy allowing the user to study the effect of passing the ball more or less often.

When employing this strategy in the `sample_play()` or `sample_drives()` functions, the argument $p$ must be included as a parameter. $p$ is the probability a given offensive play on first, second, or third down is a pass. To keep the strategy straightforward, we follow an empirical procedure when the play to be sampled is a fourth down. That is, when a fourth down situation arises in the sample, we assume the play is simply sampled from all fourth down plays at the given yardline (or within a neighborhood of the yardline) and distance to go until a first down. Fourth down plays sampled at their regular rates usually result in a punt or a field goal attempt. By varying $p$ we can study how pass proportion affects statistics such as the expected points per drive, the proportion of drives resulting in a score, among a host of other metrics. 

<!-- The proportion of passing (running) plays on first through third downs was roughly 59\% (41\%) in both 2018 and 2019.  -->

<!-- To study this strategy we generate 10000 drives starting at the 25 yard line for all plays from these two regular seasons (separately). This corresponds to the usual starting position to begin a half or after an opposing team scores (assuming the kickoff is a touchback). For each drive we use the `sample_drives()` function and set the `single_drive` argument equal to `TRUE`. Thus, we only care about simulating one drive and storing its outcome for each simulated drive. In other words, we start each drive with first down and ten yards to go from the 25 and sample plays accordingly. This strategy samples a play using `sample_play()` from the set of all plays matching those conditions. The package updates the down, distance, and yards to go using the `down_distance_updater()` function and samples another play from all plays satisfying the updated criteria. We repeat this process until the team on offense either scores or turns the ball over (either on downs or via a turnover). -->

Figure \ref{fig:pass-rush-all-facet} shows the proportion of simulated drives resulting in a score for the offensive team (field goal or touchdown) in 2018 and 2019. Note that we include a vertical dashed line showing the league-wide proportion of passing plays on first through third downs. This proportion of passing (running) plays on first through third downs was roughly 59\% (41\%) in both 2018 and 2019. At first inspection this figure suggests passing more often results in scoring **less** on average. Obviously this initial glance requires more scrutiny and indeed, subsetting by the type of score reveals additional insight. Specifically, Figure \ref{fig:pass-rush-by-type} shows the same data subsetted by the type of score: either a touchdown or field goal. There is a clear trend showing more touchdowns are scored as the proportion of plays that are passes increases. 

```{r pass-rush-all-facet, fig.width = 4, fig.height=3, fig.cap = "\\label{fig:pass-rush-all-facet}The percentage of simulated drives that resulted in a score (touchdown or field goal) in 2018 and 2019. The dashed line represents the actual proportion of passing plays on first, second, and third downs in both years.", echo = F}
p <- ggplot(data = all_scores,
            aes(x = proportion, y = p))
p + geom_point(alpha = .75, size = 1) +
  geom_errorbar(aes(ymin = lower, ymax = upper), alpha = .75) +
  facet_grid(rows = "full_year") +
  geom_smooth(color = "black",method = "loess") +
  geom_vline(aes(xintercept = .59), col = "grey50", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 1, by = .2)) +
  scale_y_continuous(limits = c(.3, .6), breaks = seq(.35, .6, by = .1),
                     #labels = scales::percent,
                     labels = percent_format(accuracy = 1)) +
  scale_color_brewer(palette = "Dark2") +
  labs(x = "Proportion Pass", y = "Percent Score") +
  guides(fill = F) +
  theme_bw()
```

```{r, pass-rush-by-type, fig.width = 4.2, fig.height=3, fig.cap = "\\label{fig:pass-rush-by-type}The percentage of simulated drives that resulted in either a touchdown (orange) or a field goal (green) in 2018 and 2019. The dashed line represents the actual proportion of passing plays on first, second, and third downs in both years.", echo = F}
p <- ggplot(data = subset(all_scores_by_type, 
                          score_type %in% c("FG", "TD")),
            aes(x = proportion, y = p, col = score_type, group = score_type))
# suppressWarnings(p + geom_point(position = position_dodge(width = .05)) +
p + geom_point(position = position_dodge(width = .05), alpha = .5, size = 1) +
#  geom_smooth(aes(col = score_type),method = "loess") +
  geom_errorbar(aes(ymin = lower, ymax = upper),
                position = position_dodge(width = .05), alpha = .5) +
  facet_grid(rows = "full_year") +
  geom_vline(aes(xintercept = .59), col = "grey50", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 1, by = .2)) +
  scale_y_continuous(limits = c(0.05, .5), breaks = seq(0, .5, by = .1),
                     #labels = scales::percent,
                     labels = percent_format(accuracy = 1)) +
  scale_color_brewer("type", palette = "Dark2") +
  labs(x = "Proportion Pass", y = "Percent Score") +
  guides(col = F) +
  theme_bw() +
  theme(legend.title = element_blank())
```

Next, we look at the percentage of drives resulting in a score broken down by the quality of the team. In this case we subset by whether or not a team made the playoffs, and use playoff appearance as a proxy for quality. To do this we simulate one set of drives using plays from teams that made the playoffs and another set of drives for teams that did not. Figure \ref{fig:pass-rush-facet} shows drives using plays from the better teams (i.e., playoff teams) tend to result in a score more often when employing a heavier passing-based strategy than the drives from non-playoff teams. 

```{r pass-rush-facet, fig.width = 4.25, fig.height=3.25, fig.cap = "\\label{fig:pass-rush-facet} The percentage of simulated drives that resulted in a score by type (touchdown or field goal) in 2018 and 2019 colored by playoff teams (orange) versus non-playoff teams (purple).", echo = F}
p <- ggplot(data = subset(scores, score_type %in% c("FG", "TD")),
            aes(x = proportion, y = p, col = playoffs))
p + geom_point(position = position_dodge(width = .05), alpha = .5, size = 1) +
#  geom_smooth(aes(col = playoffs),method = "loess",show.legend = T) +
  geom_errorbar(aes(ymin = lower, ymax = upper), 
                position = position_dodge(.05),
                alpha = .5) +
  facet_grid(year ~ score_type) +
  geom_vline(aes(xintercept = .59), col = "grey50", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 1, by = .2)) +
  scale_y_continuous(#labels = scales::percent,
                      labels = percent_format(accuracy = 1)) +
  #scale_color_brewer(palette = "Set1") +
  scale_colour_manual(values = c("No" = "#984EA3" ,"Yes"="#FF7F00"))+
  labs(x = "Proportion Pass", y = "Percent Score") +
  guides(col = F) +
  theme_bw()
```

Again, we stress that our approach is not causal in any sense of the imagination. That is, we are not saying that passing more will necessarily lead to more scores, particularly if the team has a sub-standard quarterback. This result, of course, is likely confounded by playoff teams (traditionally) having better quarterbacks. Thus, we next subset the pool of plays by each team's overall passer rating (RTG) and sample plays from three distinct pools: High, Medium, and Low passer rating teams. A team in the pool of High passer rating teams had an overall rating falling into the upper-most tercile of teams. The pools for Medium and Low are similarly defined. The results of the simulated drives using these groups are displayed in Figure \ref{fig:pass-rush-qbr}. Here, we see the teams in the upper tercile of passing ratings score more touchdowns as the proportion of passing plays increases than teams in the other two groups. However, the percent field goals scored as a function of the proportion of passing plays is similar for all the three team groupings.

```{r pass-rush-qbr, fig.width = 4, fig.height=3, fig.cap = "\\label{fig:pass-rush-qbr}The percentage of simulated drives that resulted in a score by type (touchdown or field goal) in 2018 and 2019 colored by overall team passer rating classification: High (green), Medium (purple), and Low (orange).", echo = F}
p <- ggplot(data = subset(qbr_scores, score_type %in% c("FG", "TD")),
                  aes(x = proportion, y = p, color = qbr_short)) 
p + geom_point(position = position_dodge(width = .05), alpha = .5, size = 1) +
#  geom_smooth(aes(col = qbr_short),method = "loess") +
  geom_errorbar(aes(ymin = lower, ymax = upper), 
                position = position_dodge(.05), 
                alpha = .5) +
  facet_grid(full_year ~ score_type) + 
  geom_vline(aes(xintercept = .59), col = "grey50", linetype = "dashed") +
  scale_color_brewer("RTG", palette = "Dark2") +
  labs(x = "Proportion Pass", y = "Percent Score") +
  scale_x_continuous(breaks = c(seq(0, 1, by = .2))) + 
  scale_y_continuous(breaks = seq(0.0, .5, by = .1), limits = c(0.05, .5),
                     #labels = scales::percent,
                     labels = percent_format(accuracy = 1)) + 
  guides(col = F) +
  theme_bw()

```

Our overall conclusion, based on these simulations, is that passing more should lead to a higher percentage of touchdowns scored. This conclusion is not uniformly true across all types of teams, however. That is, the better teams, or those teams with a higher-quality quarterback relative to the rest of the teams in the league, will benefit much more than the others.

# Conclusions and Discussion {#sec:conc}

Even though the NFL has existed since 1920 teams are still seeking inefficencies in the game to exploit. There always seems to be a brilliant new coach ready to introduce a new strategy to push teams to more success. The purpose of creating `NFLSimulatoR` is to give the wider community a tool to examine a multitude of NFL strategies. The package contains a set of robust and statistically sound tools to simulate plays and drives to examine NFL game plans. This package will also age well as it can be continually updated with data from the most recent NFL season. Another use for the package is to examine the ramifications of rule changes by the league. This would allow the league to take a data-driven approach to such changes. One example of a rule change that has been debated is eliminating the kickoff after a score.

In the package we include two strategies of interest, passing versus rushing the ball and going for it or not on fourth down. We have examined each strategy in this paper as examples of possibilities for the package. We imagine many extensions of our work, including strategies regarding whether to run or throw on first down, what play works best after a penalty or timeout, and what plays to run in the first or last few minutes of a game or quarter. 

<!-- For reproducibility, we have included the data and code used for this paper at [Placeholder for code/data repository]. -->

We welcome collaboration from the sports analytics community and hope for contributions to our package, which are easy to make given its open-source nature. The initial reception of our package in the analytics community (over 1000 downloads within the first two months of widespread availability) is incredibly humbling and encouraging. The fact that there are so many possible analysis options of these strategies makes us more excited about the existence of the `NFLSimulatoR` package, because now the wider sports analytics community can take our initial work and extend it. 
As an example, very recently a new model-based fourth down decision maker was introduced by Ben Baldwin, an author of the previously mentioned `nflfastR` package @baldwin_athletic. This is exactly the sort of contribution we hope will be added to the `NFLSimulatoR` package. Such a strategy could be integrated and tested within the simulation based framework we created and shared with the community at large. We look forward to what new strategies will be devised and tested and hope to see even more analytics used in the NFL and other sports leagues.

# References {-}